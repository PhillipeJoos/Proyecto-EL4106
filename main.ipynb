{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69090f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torchaudio\n",
    "from torch import nn\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn.functional as F\n",
    "from random import randint\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix\n",
    "import os\n",
    "import re\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc20f275",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c354a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CustomSpeechCommands(Dataset):\n",
    "    def __init__(self, root, files_list, download=False, target_len=16000):\n",
    "        \"\"\"\n",
    "        root: directorio raíz del dataset\n",
    "        files_list: archivo con lista de paths (train/val/test)\n",
    "        download: True para descargar dataset si no existe\n",
    "        target_len: duración fija en muestras (16000 = 1s)\n",
    "        \"\"\"\n",
    "        self.target_len = target_len\n",
    "        self.dataset = torchaudio.datasets.SPEECHCOMMANDS(\n",
    "            root=root, \n",
    "            download=download\n",
    "        )\n",
    "        self.indices = None\n",
    "        self.splitter(files_list, root)\n",
    "        # self.OFFICIAL_CLASSES = [\n",
    "        # \"yes\", \"no\", \"up\", \"down\", \"left\", \"right\",\n",
    "        # \"on\", \"off\", \"stop\", \"go\"\n",
    "        # ]\n",
    "\n",
    "    def splitter(self, files_list, root):\n",
    "        with open(files_list, 'r') as f:\n",
    "            self.file_paths = [line.strip() for line in f.readlines()]\n",
    "        \n",
    "        self.all_paths = []\n",
    "        for item in tqdm(self.dataset._walker, desc=f\"Splitting {files_list}\"):\n",
    "            full_path = item\n",
    "            relative_path = os.path.relpath(\n",
    "                full_path, \n",
    "                start=os.path.join(root, \"SpeechCommands\", \"speech_commands_v0.02\")\n",
    "            )\n",
    "            relative_path = relative_path.replace(\"\\\\\", \"/\")\n",
    "            self.all_paths.append(relative_path)\n",
    "\n",
    "        self.indices = [\n",
    "            i for i, path in enumerate(self.all_paths) \n",
    "            if path in self.file_paths\n",
    "        ]\n",
    "\n",
    "        print(f\"Total archivos en dataset: {len(self.all_paths)}\")\n",
    "        print(f\"Archivos en {files_list}: {len(self.file_paths)}\")\n",
    "        print(f\"Archivos encontrados: {len(self.indices)}\")\n",
    "\n",
    "    def pad_waveform(self, waveform):\n",
    "        \"\"\"\n",
    "        Aplica zero padding (o recorte) para dejar todas las señales del mismo largo.\n",
    "        \"\"\"\n",
    "        length = waveform.shape[-1]\n",
    "        if length < self.target_len:\n",
    "            pad_amt = self.target_len - length\n",
    "            waveform = F.pad(waveform, (0, pad_amt))\n",
    "        elif length > self.target_len:\n",
    "            waveform = waveform[:, :self.target_len]\n",
    "        return waveform\n",
    "\n",
    "    def extract_features(self, feature_extractor, device=\"cpu\"):\n",
    "        \"\"\"\n",
    "        Extrae características (MFCC u otras) aplicando zero padding en el waveform.\n",
    "        Devuelve:\n",
    "          - features: tensor N x C x T\n",
    "          - labels: lista de strings\n",
    "        \"\"\"\n",
    "        features = []\n",
    "        labels = []\n",
    "\n",
    "        feature_extractor.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for idx in tqdm(self.indices, desc=\"Extrayendo features\"):\n",
    "                waveform, sample_rate, label, _, _ = self.dataset[idx]\n",
    "\n",
    "                # padding antes del extractor\n",
    "                waveform = self.pad_waveform(waveform).to(device)\n",
    "\n",
    "                feat = feature_extractor(waveform).squeeze(0).cpu()\n",
    "                feat = feat.transpose(0, 1)  # [T, n_mfcc] -> ahora input_size=13\n",
    "                features.append(feat)\n",
    "                labels.append(label)\n",
    "\n",
    "        # Convertir a tensor (todas las secuencias tienen igual longitud ahora)\n",
    "        features = torch.stack(features)\n",
    "        print(f\"Features tensor: {features.shape}\")  # [N, n_mfcc, T]\n",
    "        return features, labels\n",
    "\n",
    "\n",
    "    def save_features(self, feature_extractor, save_path, device=\"cpu\"):\n",
    "        \"\"\"\n",
    "        Extrae y guarda features, reemplazando clases no oficiales por 'unknown'.\n",
    "        \"\"\"\n",
    "        print(f\"Guardando features en: {save_path}\")\n",
    "        try:\n",
    "            features, labels = self.extract_features(feature_extractor, device=device)\n",
    "            # processed_labels = [\n",
    "            #     label if label in self.OFFICIAL_CLASSES else \"unknown\"\n",
    "            #     for label in labels\n",
    "            # ]\n",
    "            torch.save({\"features\": features, \"labels\": labels}, save_path)\n",
    "            print(f\"Features guardadas correctamente en {save_path}\")\n",
    "            print(f\"Clases finales: {set(labels)}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error al guardar features en {save_path}: {e}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        original_idx = self.indices[idx]\n",
    "        waveform, sample_rate, label, speaker_id, utterance_number = self.dataset[original_idx]\n",
    "        waveform = self.pad_waveform(waveform)\n",
    "        return waveform, sample_rate, label, speaker_id, utterance_number\n",
    "\n",
    "class FeaturesDataset(Dataset):\n",
    "    def __init__(self, features_path):\n",
    "        \"\"\"\n",
    "        Carga un archivo .pt con 'features' y 'labels' previamente guardados.\n",
    "\n",
    "        features_path: ruta al archivo .pt (por ejemplo 'data/train.pt')\n",
    "        \"\"\"\n",
    "        data = torch.load(features_path)\n",
    "        self.features = data[\"features\"]\n",
    "        self.labels = data[\"labels\"]\n",
    "\n",
    "        # Crear diccionario para pasar de string a índice (útil para entrenar)\n",
    "        self.label_to_idx = {label: i for i, label in enumerate(sorted(set(self.labels)))}\n",
    "        self.idx_to_label = {v: k for k, v in self.label_to_idx.items()}\n",
    "        self.numeric_labels = torch.tensor([self.label_to_idx[l] for l in self.labels])\n",
    "\n",
    "        print(f\"Dataset cargado desde {features_path}\")\n",
    "        print(f\" - {len(self.features)} ejemplos\")\n",
    "        print(f\" - {len(self.label_to_idx)} clases\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        feature = self.features[idx]\n",
    "        label = self.numeric_labels[idx]\n",
    "        return feature, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e834f86",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32de13b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        rnn_type,\n",
    "        n_input_channels,\n",
    "        hidd_size=256,\n",
    "        out_features = 35,\n",
    "        num_layers=1,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Para utilizar una vanilla RNN entregue rnn_type=\"RNN\"\n",
    "        Para utilizar una LSTM entregue rnn_type=\"LSTM\"\n",
    "        Para utilizar una GRU entregue rnn_type=\"GRU\"\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.rnn_type = rnn_type\n",
    "\n",
    "        if rnn_type == \"GRU\":\n",
    "            self.rnn_layer = nn.GRU(n_input_channels, hidd_size, batch_first=True, num_layers=num_layers)\n",
    "\n",
    "        elif rnn_type == \"LSTM\":\n",
    "            self.rnn_layer = nn.LSTM(n_input_channels, hidd_size, batch_first=True, num_layers=num_layers)\n",
    "\n",
    "        elif rnn_type == \"RNN\":\n",
    "            self.rnn_layer = nn.RNN(n_input_channels, hidd_size, batch_first=True, num_layers=num_layers, bidirectional=True)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"rnn_type {rnn_type} not supported.\")\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(hidd_size, out_features),\n",
    "        )\n",
    "\n",
    "        self.flatten_layer = nn.Flatten()\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.rnn_type == \"GRU\":\n",
    "            out, h = self.rnn_layer(x)\n",
    "\n",
    "        elif self.rnn_type == \"LSTM\":\n",
    "            out, (h, c) = self.rnn_layer(x)\n",
    "\n",
    "        elif self.rnn_type == \"RNN\":\n",
    "            out, h = self.rnn_layer(x)\n",
    "\n",
    "        out = h[-1]\n",
    "\n",
    "        return self.net(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b8e3a4",
   "metadata": {},
   "source": [
    "## Trainers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5b7f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(x_batch, y_batch, model, optimizer, criterion, use_gpu):\n",
    "    # Predicción\n",
    "    y_predicted = model(x_batch)\n",
    "\n",
    "    # Cálculo de loss\n",
    "    loss = criterion(y_predicted, y_batch)\n",
    "\n",
    "    # Actualización de parámetros\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return y_predicted, loss\n",
    "\n",
    "\n",
    "def evaluate(val_loader, model, criterion, use_gpu):\n",
    "    cumulative_loss = 0\n",
    "    cumulative_predictions = 0\n",
    "    data_count = 0\n",
    "\n",
    "    for x_val, y_val in val_loader:\n",
    "        if use_gpu:\n",
    "            x_val = x_val.cuda()\n",
    "            y_val = y_val.cuda()\n",
    "\n",
    "        y_predicted = model(x_val)\n",
    "\n",
    "        loss = criterion(y_predicted, y_val)\n",
    "\n",
    "        class_prediction = torch.argmax(y_predicted, axis=1).long()\n",
    "\n",
    "        cumulative_predictions += (y_val == class_prediction).sum().item()\n",
    "        cumulative_loss += loss.item() * y_val.shape[0]\n",
    "        data_count += y_val.shape[0]\n",
    "\n",
    "    val_acc = cumulative_predictions / data_count\n",
    "    val_loss = cumulative_loss / data_count\n",
    "\n",
    "    return val_acc, val_loss\n",
    "\n",
    "\n",
    "def train_model(\n",
    "    model,\n",
    "    train_dataset,\n",
    "    val_dataset,\n",
    "    epochs,\n",
    "    criterion,\n",
    "    batch_size,\n",
    "    lr,\n",
    "    n_evaluations_per_epoch=6,\n",
    "    use_gpu=False,\n",
    "):\n",
    "    if use_gpu:\n",
    "        model.cuda()\n",
    "\n",
    "    # Definición de dataloader\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=use_gpu)\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False, pin_memory=use_gpu)\n",
    "\n",
    "    # Optimizador\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, betas=(0.9, 0.98), eps=1e-9)\n",
    "\n",
    "    # Listas para guardar curvas de entrenamiento\n",
    "    curves = {\n",
    "        \"train_acc\": [],\n",
    "        \"val_acc\": [],\n",
    "        \"train_loss\": [],\n",
    "        \"val_loss\": [],\n",
    "    }\n",
    "\n",
    "    t0 = time.perf_counter()\n",
    "\n",
    "    iteration = 0\n",
    "\n",
    "    n_batches = len(train_loader)\n",
    "    print(n_batches)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"\\rEpoch {epoch + 1}/{epochs}\")\n",
    "        cumulative_train_loss = 0\n",
    "        cumulative_train_corrects = 0\n",
    "        examples_count = 0\n",
    "\n",
    "        # Entrenamiento del modelo\n",
    "        model.train()\n",
    "        for i, (x_batch, y_batch) in enumerate(train_loader):\n",
    "            if use_gpu:\n",
    "                x_batch = x_batch.cuda()\n",
    "                y_batch = y_batch.cuda()\n",
    "\n",
    "            y_predicted, loss = train_step(x_batch, y_batch, model, optimizer, criterion, use_gpu)\n",
    "\n",
    "            cumulative_train_loss += loss.item() * x_batch.shape[0]\n",
    "            examples_count += y_batch.shape[0]\n",
    "\n",
    "            # Calculamos número de aciertos\n",
    "            class_prediction = torch.argmax(y_predicted, axis=1).long()\n",
    "            cumulative_train_corrects += (y_batch == class_prediction).sum().item()\n",
    "\n",
    "            if (i % (n_batches // n_evaluations_per_epoch) == 0) and (i > 0):\n",
    "                train_loss = cumulative_train_loss / examples_count\n",
    "                train_acc = cumulative_train_corrects / examples_count\n",
    "\n",
    "                print(f\"Iteration {iteration} - Batch {i}/{len(train_loader)} - Train loss: {train_loss}, Train acc: {train_acc}\")\n",
    "\n",
    "            iteration += 1\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_acc, val_loss = evaluate(val_loader, model, criterion, use_gpu)\n",
    "\n",
    "        print(f\"Val loss: {val_loss}, Val acc: {val_acc}\")\n",
    "\n",
    "        train_loss = cumulative_train_loss / examples_count\n",
    "        train_acc = cumulative_train_corrects / examples_count\n",
    "\n",
    "        curves[\"train_acc\"].append(train_acc)\n",
    "        curves[\"val_acc\"].append(val_acc)\n",
    "        curves[\"train_loss\"].append(train_loss)\n",
    "        curves[\"val_loss\"].append(val_loss)\n",
    "\n",
    "    print()\n",
    "    total_time = time.perf_counter() - t0\n",
    "    print(f\"Tiempo total de entrenamiento: {total_time:.4f} [s]\")\n",
    "\n",
    "    model.cpu()\n",
    "\n",
    "    return curves, total_time\n",
    "\n",
    "def show_curves(all_curves, suptitle=''):\n",
    "    final_curve_means = {k: np.mean([c[k] for c in all_curves], axis=0) for k in all_curves[0].keys()}\n",
    "    final_curve_stds = {k: np.std([c[k] for c in all_curves], axis=0) for k in all_curves[0].keys()}\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(13, 5))\n",
    "    fig.set_facecolor('white')\n",
    "\n",
    "    epochs = np.arange(len(final_curve_means[\"val_loss\"])) + 1\n",
    "\n",
    "    # ==== Plot de pérdidas ====\n",
    "    ax[0].plot(epochs, final_curve_means['val_loss'], label='validation')\n",
    "    ax[0].plot(epochs, final_curve_means['train_loss'], label='training')\n",
    "    ax[0].fill_between(epochs, \n",
    "                       y1=final_curve_means[\"val_loss\"] - final_curve_stds[\"val_loss\"], \n",
    "                       y2=final_curve_means[\"val_loss\"] + final_curve_stds[\"val_loss\"], alpha=.5)\n",
    "    ax[0].fill_between(epochs, \n",
    "                       y1=final_curve_means[\"train_loss\"] - final_curve_stds[\"train_loss\"], \n",
    "                       y2=final_curve_means[\"train_loss\"] + final_curve_stds[\"train_loss\"], alpha=.5)\n",
    "    ax[0].set_xlabel('Epoch')\n",
    "    ax[0].set_ylabel('Loss')\n",
    "    ax[0].set_title('Loss evolution during training')\n",
    "    ax[0].legend()\n",
    "\n",
    "    # ==== Plot de precisión ====\n",
    "    ax[1].plot(epochs, final_curve_means['val_acc'], label='validation')\n",
    "    ax[1].plot(epochs, final_curve_means['train_acc'], label='training')\n",
    "    ax[1].fill_between(epochs, \n",
    "                       y1=final_curve_means[\"val_acc\"] - final_curve_stds[\"val_acc\"], \n",
    "                       y2=final_curve_means[\"val_acc\"] + final_curve_stds[\"val_acc\"], alpha=.5)\n",
    "    ax[1].fill_between(epochs, \n",
    "                       y1=final_curve_means[\"train_acc\"] - final_curve_stds[\"train_acc\"], \n",
    "                       y2=final_curve_means[\"train_acc\"] + final_curve_stds[\"train_acc\"], alpha=.5)\n",
    "    ax[1].set_xlabel('Epoch')\n",
    "    ax[1].set_ylabel('Accuracy')\n",
    "    ax[1].set_title('Accuracy evolution during training')\n",
    "    ax[1].legend()\n",
    "\n",
    "    fig.suptitle(suptitle, fontsize=16, weight=\"bold\")\n",
    "\n",
    "    # ==== Guardar y cerrar ====\n",
    "    filepath = os.path.join('img', f'{suptitle}.pdf')\n",
    "    plt.savefig(filepath, bbox_inches='tight', format='pdf')\n",
    "    plt.close(fig)  \n",
    "\n",
    "def get_metrics_and_confusion_matrix(models, dataset, name=''):\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=min(16, len(dataset)))\n",
    "\n",
    "    # === Obtener etiquetas verdaderas ===\n",
    "    y_true = []\n",
    "    for _, y in dataloader:\n",
    "        y_true.append(y)\n",
    "    y_true = torch.cat(y_true)\n",
    "    n_classes = len(torch.unique(y_true))\n",
    "\n",
    "    # === Definir labels ===\n",
    "    if hasattr(dataset, 'idx_to_label'):\n",
    "        labels = [dataset.idx_to_label[i] for i in range(n_classes)]\n",
    "    elif hasattr(dataset, 'labels'):\n",
    "        labels = dataset.labels\n",
    "    else:\n",
    "        labels = [str(i) for i in range(n_classes)]\n",
    "\n",
    "    # === Calcular matrices de confusión ===\n",
    "    cms = []\n",
    "    for model in models:\n",
    "        model.cpu()\n",
    "        model.eval()\n",
    "        y_pred = []\n",
    "        for x, _ in dataloader:\n",
    "            y_pred.append(model(x).argmax(dim=1))\n",
    "        y_pred = torch.cat(y_pred)\n",
    "\n",
    "        cm = confusion_matrix(y_true, y_pred, labels=range(n_classes), normalize='true')\n",
    "        cms.append(cm)\n",
    "\n",
    "    cms = np.stack(cms)\n",
    "    cm_mean = cms.mean(axis=0)\n",
    "    cm_std = cms.std(axis=0)\n",
    "\n",
    "    # === Accuracy promedio ===\n",
    "    accs = []\n",
    "    for model in models:\n",
    "        y_pred = []\n",
    "        for x, _ in dataloader:\n",
    "            y_pred.append(model(x).argmax(dim=1))\n",
    "        y_pred = torch.cat(y_pred)\n",
    "        accs.append(accuracy_score(y_true, y_pred))\n",
    "\n",
    "    acc_mean = np.mean(accs) * 100\n",
    "    acc_std = np.std(accs) * 100\n",
    "\n",
    "    # === Figura combinada ===\n",
    "    os.makedirs('img', exist_ok=True)\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "    # --- Subplot 1: medias ---\n",
    "    im1 = axs[0].imshow(cm_mean, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    axs[0].set_title('Mean Confusion Matrix')\n",
    "    axs[0].set_xlabel('Predicted label')\n",
    "    axs[0].set_ylabel('True label')\n",
    "    axs[0].set_xticks(np.arange(n_classes))\n",
    "    axs[0].set_yticks(np.arange(n_classes))\n",
    "    axs[0].set_xticklabels(labels, rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "    axs[0].set_yticklabels(labels)\n",
    "    fig.colorbar(im1, ax=axs[0], fraction=0.046, pad=0.04)\n",
    "\n",
    "    # --- Subplot 2: desviaciones estándar ---\n",
    "    im2 = axs[1].imshow(cm_std, interpolation='nearest', cmap=plt.cm.Oranges)\n",
    "    axs[1].set_title('Standard Deviation')\n",
    "    axs[1].set_xlabel('Predicted label')\n",
    "    axs[1].set_ylabel('True label')\n",
    "    axs[1].set_xticks(np.arange(n_classes))\n",
    "    axs[1].set_yticks(np.arange(n_classes))\n",
    "    axs[1].set_xticklabels(labels, rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "    axs[1].set_yticklabels(labels)\n",
    "    fig.colorbar(im2, ax=axs[1], fraction=0.046, pad=0.04)\n",
    "\n",
    "    # --- Título general ---\n",
    "    fig.suptitle(rf'{name}, mean acc = {acc_mean:.2f} ± {acc_std:.2f}%', fontsize=12)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "\n",
    "    filepath = os.path.join('img', f'conf_mat_{name}.pdf')\n",
    "    plt.savefig(filepath, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "\n",
    "    print(f\"Combined confusion matrix (mean + std) saved to {filepath}\")\n",
    "\n",
    "def evaluate_with_std(model, dataloader, criterion, use_gpu=True):\n",
    "    # jaja std\n",
    "    if use_gpu:\n",
    "        model.cuda()\n",
    "\n",
    "    all_losses = []\n",
    "    all_accuracies = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            if use_gpu:\n",
    "                X, y = X.cuda(non_blocking=True), y.cuda(non_blocking=True)\n",
    "\n",
    "            outputs = model(X)\n",
    "            loss = criterion(outputs, y)\n",
    "            all_losses.append(loss.item())\n",
    "\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            acc = (preds == y).float().mean().item()\n",
    "            all_accuracies.append(acc)\n",
    "\n",
    "    mean_loss = np.mean(all_losses)\n",
    "    std_loss = np.std(all_losses)\n",
    "    mean_acc = np.mean(all_accuracies)\n",
    "    std_acc = np.std(all_accuracies)\n",
    "\n",
    "    model.cpu()\n",
    "\n",
    "    return mean_acc, std_acc, mean_loss, std_loss\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_models_metrics(models, dataloader, criterion, use_gpu=True):\n",
    "    \"\"\"\n",
    "    Evalúa múltiples modelos y calcula métricas promedio y desviación estándar.\n",
    "    Retorna un diccionario con accuracy, recall, precision y f1\n",
    "    \"\"\"\n",
    "\n",
    "    # Diccionarios para guardar resultados\n",
    "    all_metrics = {\n",
    "        \"accuracy\": [],\n",
    "        \"recall\": [],\n",
    "        \"precision\": [],\n",
    "        \"f1\": [],\n",
    "    }\n",
    "\n",
    "    for model in models:\n",
    "        model.eval()\n",
    "        if use_gpu:\n",
    "            model.cuda()\n",
    "\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        losses = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for X, y in dataloader:\n",
    "                if use_gpu:\n",
    "                    X, y = X.cuda(non_blocking=True), y.cuda(non_blocking=True)\n",
    "\n",
    "                outputs = model(X)\n",
    "                loss = criterion(outputs, y)\n",
    "                losses.append(loss.item())\n",
    "\n",
    "                preds = outputs.argmax(dim=1)\n",
    "                y_true.extend(y.cpu().numpy())\n",
    "                y_pred.extend(preds.cpu().numpy())\n",
    "\n",
    "        # Cálculo de métricas\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        rec = recall_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "        prec = precision_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "        f1 = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "        loss_mean = np.mean(losses)\n",
    "\n",
    "        # Guardar métricas\n",
    "        all_metrics[\"accuracy\"].append(acc)\n",
    "        all_metrics[\"recall\"].append(rec)\n",
    "        all_metrics[\"precision\"].append(prec)\n",
    "        all_metrics[\"f1\"].append(f1)\n",
    "\n",
    "        if use_gpu:\n",
    "            model.cuda()\n",
    "        else:\n",
    "            model.cpu()\n",
    "\n",
    "    # Calcular medias y desviaciones estándar\n",
    "    metrics_mean = {k: np.mean(v) for k, v in all_metrics.items()}\n",
    "    metrics_std = {k: np.std(v) for k, v in all_metrics.items()}\n",
    "\n",
    "    print(\"\\n=== Resultados promedio sobre modelos ===\")\n",
    "    for metric in all_metrics.keys():\n",
    "        print(f\"{metric.capitalize():<10}: {metrics_mean[metric]:.4f} +/- {metrics_std[metric]:.4f}\")\n",
    "\n",
    "    print(\"\\n=== Detalles por modelo ===\")\n",
    "    for i, model in enumerate(models):\n",
    "        print(f\"\\n=== Modelo {i + 1} ({model.rnn_type}) ===\")\n",
    "        for metric in all_metrics.keys():\n",
    "            print(f\"{metric.capitalize():<10}: {all_metrics[metric][i]:.4f} +/- {metrics_std[metric]:.4f}\")\n",
    "\n",
    "    # return metrics_mean, metrics_std, all_metrics\n",
    "    return\n",
    "\n",
    "def nfft_hop_length_exp(n_trains, feature_xtractor, batch_size, lr, epochs, criterion, use_gpu = True):\n",
    "    \n",
    "    # ======== Estructuras de resultados ========\n",
    "    results = {}  # {(nfft, hl): [accuracies]}\n",
    "    times_of_training = {}\n",
    "    models = {}\n",
    "\n",
    "    # ======== Obtener combinaciones de archivos ========\n",
    "    base_dir = os.path.join('data', 'petes')  # o 'data' si están en esa carpeta\n",
    "    files = os.listdir(base_dir)\n",
    "\n",
    "    # Extraer parámetros nfft y hop_length de los nombres\n",
    "    pattern = re.compile(r'n(\\d+)_hl(\\d+)')\n",
    "    pairs = sorted(list({pattern.search(f).groups() for f in files if pattern.search(f)}))\n",
    "\n",
    "    # ======== Loop sobre combinaciones ========\n",
    "    for nfft, hl in pairs:\n",
    "        nfft = int(nfft)\n",
    "        hl = int(hl)\n",
    "        print(f\"\\n=== Entrenando para nfft={nfft}, hop_length={hl} ===\")\n",
    "\n",
    "        # Cargar datasets\n",
    "        train_dataset = feature_xtractor(os.path.join(base_dir, f'train_n{nfft}_hl{hl}.pt'))\n",
    "        test_dataset = feature_xtractor(os.path.join(base_dir, f'test_n{nfft}_hl{hl}.pt'))\n",
    "        val_dataset = feature_xtractor(os.path.join(base_dir, f'val_n{nfft}_hl{hl}.pt'))\n",
    "\n",
    "        accs = []\n",
    "        train_times = []\n",
    "\n",
    "        for k in range(n_trains):\n",
    "            print(f'  Entrenando modelo {k+1}/{n_trains}')\n",
    "            model = RNNModel(rnn_type='RNN', n_input_channels=13, hidd_size=128)\n",
    "            all_curves, times = train_model(\n",
    "                model, train_dataset, val_dataset, epochs, criterion,\n",
    "                batch_size, lr, n_evaluations_per_epoch=3, use_gpu=use_gpu\n",
    "            )\n",
    "\n",
    "            val_acc = all_curves[\"val_acc\"][-1]  # o la métrica final que uses\n",
    "            accs.append(val_acc)\n",
    "            train_times.append(times)\n",
    "            models[(nfft, hl, k)] = model\n",
    "\n",
    "        results[(nfft, hl)] = accs\n",
    "        times_of_training[(nfft, hl)] = train_times\n",
    "\n",
    "    # ======== Graficar resultados ========\n",
    "    # === Procesar los resultados ===\n",
    "    nfft_vals = sorted(set(k[0] for k in results.keys()))\n",
    "    hl_vals   = sorted(set(k[1] for k in results.keys()))\n",
    "\n",
    "    # Crear matrices de promedio y desviación estándar\n",
    "    mean_matrix = np.zeros((len(hl_vals), len(nfft_vals)))\n",
    "    std_matrix  = np.zeros((len(hl_vals), len(nfft_vals)))\n",
    "\n",
    "    for i, hl in enumerate(hl_vals):\n",
    "        for j, nfft in enumerate(nfft_vals):\n",
    "            if (nfft, hl) in results:\n",
    "                vals = np.array(results[(nfft, hl)])\n",
    "                mean_matrix[i, j] = np.mean(vals)\n",
    "                std_matrix[i, j]  = np.std(vals)\n",
    "            else:\n",
    "                mean_matrix[i, j] = np.nan\n",
    "                std_matrix[i, j]  = np.nan\n",
    "\n",
    "    # === Graficar el mapa de calor ===\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    im = plt.imshow(mean_matrix, cmap='viridis', origin='lower', aspect='auto')\n",
    "\n",
    "    # Etiquetas\n",
    "    plt.xticks(range(len(nfft_vals)), nfft_vals)\n",
    "    plt.yticks(range(len(hl_vals)), hl_vals)\n",
    "    plt.xlabel('n_fft')\n",
    "    plt.ylabel('hop_length')\n",
    "    plt.title('Accuracy promedio ± desviación (5 entrenamientos por configuración)')\n",
    "\n",
    "    # Barra de color\n",
    "    cbar = plt.colorbar(im)\n",
    "    cbar.set_label('Accuracy promedio')\n",
    "\n",
    "    # Mostrar valores promedio ± std en cada celda\n",
    "    for i in range(len(hl_vals)):\n",
    "        for j in range(len(nfft_vals)):\n",
    "            mean_val = mean_matrix[i, j]\n",
    "            std_val  = std_matrix[i, j]\n",
    "            if not np.isnan(mean_val):\n",
    "                color = 'white' if mean_val < 0.7 else 'black'\n",
    "                plt.text(j, i, f\"+/-{std_val:.4f}\", \n",
    "                        ha='center', va='center', color=color, fontsize=6)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818c360d",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b30a07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_waveform(wf, sample_rate, label=\"\", figname=None):\n",
    "    \"\"\"\n",
    "    Muestra el waveform (izquierda) y los MFCCs (derecha) de una señal de audio.\n",
    "\n",
    "    Parámetros:\n",
    "        wf (Tensor): señal de audio [1, N] o [N]\n",
    "        sample_rate (int): frecuencia de muestreo (Hz)\n",
    "        label (str): etiqueta opcional para el título\n",
    "        figname (str): ruta para guardar la figura (si es None, solo muestra)\n",
    "    \"\"\"\n",
    "    if isinstance(wf, torch.Tensor):\n",
    "        wf = wf.squeeze().cpu()\n",
    "\n",
    "    # === Transformación MFCC ===\n",
    "    mfcc_transform = torchaudio.transforms.MFCC(\n",
    "        sample_rate=sample_rate,\n",
    "        n_mfcc=13,\n",
    "        melkwargs={\"n_fft\": 320, \"hop_length\": 160, \"n_mels\": 23},\n",
    "        log_mels=True\n",
    "    )\n",
    "    mfcc = mfcc_transform(wf.unsqueeze(0)).squeeze().cpu().numpy()  # [n_mfcc, time]\n",
    "\n",
    "    # === Crear figura con 2 subplots ===\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    sns.set_style(\"whitegrid\")\n",
    "\n",
    "    # --- Waveform ---\n",
    "    time = torch.arange(0, len(wf)) / sample_rate\n",
    "    axes[0].plot(time, wf.numpy(), color=\"steelblue\", linewidth=1.0)\n",
    "    axes[0].set_title(\"Waveform\", fontsize=12)\n",
    "    axes[0].set_xlabel(\"Tiempo [s]\")\n",
    "    axes[0].set_ylabel(\"Amplitud\")\n",
    "\n",
    "    # --- MFCC ---\n",
    "    sns.heatmap(mfcc, ax=axes[1], cmap=\"viridis\", cbar=True)\n",
    "    axes[1].set_title(\"MFCCs\", fontsize=12)\n",
    "    axes[1].set_xlabel(\"Tiempo (frames)\")\n",
    "    axes[1].set_ylabel(\"Coeficiente MFCC\")\n",
    "\n",
    "    fig.suptitle(f\"Audio: {label}\", fontsize=14, y=1.02)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # === Guardar o mostrar ===\n",
    "    if figname:\n",
    "        name = os.path.join('img', f'{figname}.pdf')\n",
    "        plt.savefig(name, bbox_inches=\"tight\")\n",
    "        print(f\"Figura guardada en {name}\")\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d89760d",
   "metadata": {},
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47cce70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== Paths ====\n",
    "ROOT_DIR = 'data'\n",
    "train_pt = os.path.join(ROOT_DIR, 'train.pt')\n",
    "val_pt = os.path.join(ROOT_DIR, 'val.pt')\n",
    "test_pt = os.path.join(ROOT_DIR, 'test.pt')\n",
    "TRAIN_LIST = os.path.join(ROOT_DIR,\"train_list.txt\")\n",
    "VAL_LIST = os.path.join(ROOT_DIR, \"val_list.txt\")\n",
    "TEST_LIST = os.path.join(ROOT_DIR, \"test_list.txt\")\n",
    "\n",
    "if not os.path.isfile(train_pt):\n",
    "    train_raw = CustomSpeechCommands(ROOT_DIR, TRAIN_LIST)\n",
    "    val_raw = CustomSpeechCommands(ROOT_DIR, VAL_LIST)\n",
    "    test_raw = CustomSpeechCommands(ROOT_DIR, TEST_LIST)\n",
    "    mfcc_transform = torchaudio.transforms.MFCC(\n",
    "        sample_rate=16000,\n",
    "        n_mfcc=13, # número de coeficientes MFCC a extraer\n",
    "        melkwargs={\"n_fft\": 320, \"hop_length\": 160, \"n_mels\": 23}, # 320 = 20ms, 160 = 10ms, 23 = número de filtros mel\n",
    "        log_mels = True\n",
    "    )\n",
    "    train_raw.save_features(mfcc_transform, train_pt)\n",
    "    test_raw.save_features(mfcc_transform, test_pt)\n",
    "    val_raw.save_features(mfcc_transform, val_pt)\n",
    "\n",
    "train_dataset = FeaturesDataset(train_pt)\n",
    "test_dataset = FeaturesDataset(test_pt)\n",
    "val_dataset = FeaturesDataset(val_pt)\n",
    "\n",
    "\n",
    "print(\"¡Datasets cargados exitosamente!\")\n",
    "print(f\"Train samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded16ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# random_idx = randint(0, len(test_raw))\n",
    "# waveform, sample_rate, label, *_ = test_raw[random_idx]\n",
    "\n",
    "# plot_waveform(waveform, sample_rate, label, figname=f'{label}_waveform_and_MFCC')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab517a3b",
   "metadata": {},
   "source": [
    "# Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a695a9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_dataset.features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6895b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preliminary testing\n",
    "lr = 5e-4\n",
    "batch_size = 32\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "n_trains = 2\n",
    "epochs = 2\n",
    "\n",
    "for arch in ['GRU', 'LSTM', 'RNN']:\n",
    "    print(f'Entrenando Modelo {arch}')\n",
    "    times_of_training = []\n",
    "    models = []\n",
    "    curves = []\n",
    "    for k in range(n_trains):\n",
    "        print(f'Entrenando modelo {k}/{n_trains}')\n",
    "        model = RNNModel(rnn_type = arch, n_input_channels=13) # puede ser que sea util estudiar el hidden size, o sea reducirlo hasta que comience a afectar el rendimiento del modelo en val\n",
    "        all_curves, times = train_model(model, train_dataset, val_dataset, epochs, criterion, batch_size, lr, n_evaluations_per_epoch=3, use_gpu=True)\n",
    "        curves.append(all_curves)\n",
    "        times_of_training.append(times)\n",
    "        models.append(model)\n",
    "    show_curves(curves, arch)\n",
    "    get_metrics_and_confusion_matrix(models, test_dataset, arch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2af0ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proyecto (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
