{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69090f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torchaudio\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from models import RNNModel\n",
    "from dataset import CustomSpeechCommands, FeaturesDataset\n",
    "from trainer import train_step, evaluate, train_model, show_curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f47cce70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting data/train_list.txt: 100%|██████████| 105829/105829 [00:00<00:00, 129552.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total archivos en dataset: 105829\n",
      "Archivos en data/train_list.txt: 32453\n",
      "Archivos encontrados: 32453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting data/val_list.txt: 100%|██████████| 105829/105829 [00:00<00:00, 166374.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total archivos en dataset: 105829\n",
      "Archivos en data/val_list.txt: 3875\n",
      "Archivos encontrados: 3875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting data/test_list.txt: 100%|██████████| 105829/105829 [00:00<00:00, 190726.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total archivos en dataset: 105829\n",
      "Archivos en data/test_list.txt: 4381\n",
      "Archivos encontrados: 4381\n",
      "Guardando features en: data/train.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extrayendo features:   0%|          | 0/32453 [00:00<?, ?it/s]/home/felipeipe/Documents/Proyecto-EL4106/proyecto/lib/python3.12/site-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
      "  warnings.warn(\n",
      "/home/felipeipe/Documents/Proyecto-EL4106/proyecto/lib/python3.12/site-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
      "Extrayendo features: 100%|██████████| 32453/32453 [01:16<00:00, 424.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features tensor: torch.Size([32453, 13, 101])\n",
      "Features guardadas correctamente en data/train.pt\n",
      "Clases finales: {'on', 'stop', 'right', 'yes', 'unknown', 'off', 'up', 'left', 'down', 'no', 'go'}\n",
      "Guardando features en: data/test.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extrayendo features: 100%|██████████| 4381/4381 [00:12<00:00, 355.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features tensor: torch.Size([4381, 13, 101])\n",
      "Features guardadas correctamente en data/test.pt\n",
      "Clases finales: {'on', 'stop', 'right', 'yes', 'unknown', 'off', 'up', 'left', 'down', 'no', 'go'}\n",
      "Guardando features en: data/val.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extrayendo features: 100%|██████████| 3875/3875 [00:09<00:00, 395.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features tensor: torch.Size([3875, 13, 101])\n",
      "Features guardadas correctamente en data/val.pt\n",
      "Clases finales: {'on', 'stop', 'right', 'yes', 'unknown', 'off', 'up', 'left', 'down', 'no', 'go'}\n",
      "Dataset cargado desde data/train.pt\n",
      " - 32453 ejemplos\n",
      " - 11 clases\n",
      "Dataset cargado desde data/test.pt\n",
      " - 4381 ejemplos\n",
      " - 11 clases\n",
      "Dataset cargado desde data/val.pt\n",
      " - 3875 ejemplos\n",
      " - 11 clases\n",
      "¡Datasets cargados exitosamente!\n",
      "Train samples: 32453\n",
      "Validation samples: 3875\n",
      "Test samples: 4381\n"
     ]
    }
   ],
   "source": [
    "# ==== Paths ====\n",
    "ROOT_DIR = 'data'\n",
    "train_pt = os.path.join(ROOT_DIR, 'train.pt')\n",
    "val_pt = os.path.join(ROOT_DIR, 'val.pt')\n",
    "test_pt = os.path.join(ROOT_DIR, 'test.pt')\n",
    "TRAIN_LIST = os.path.join(ROOT_DIR,\"train_list.txt\")\n",
    "VAL_LIST = os.path.join(ROOT_DIR, \"val_list.txt\")\n",
    "TEST_LIST = os.path.join(ROOT_DIR, \"test_list.txt\")\n",
    "\n",
    "if not os.path.isfile(train_pt):\n",
    "    train_raw = CustomSpeechCommands(ROOT_DIR, TRAIN_LIST)\n",
    "    val_raw = CustomSpeechCommands(ROOT_DIR, VAL_LIST)\n",
    "    test_raw = CustomSpeechCommands(ROOT_DIR, TEST_LIST)\n",
    "    mfcc_transform = torchaudio.transforms.MFCC(\n",
    "        sample_rate=16000,\n",
    "        n_mfcc=13, # número de coeficientes MFCC a extraer\n",
    "        melkwargs={\"n_fft\": 320, \"hop_length\": 160, \"n_mels\": 23}, # 320 = 20ms, 160 = 10ms, 23 = número de filtros mel\n",
    "        log_mels = True\n",
    "    )\n",
    "    train_raw.save_features(mfcc_transform, train_pt)\n",
    "    test_raw.save_features(mfcc_transform, test_pt)\n",
    "    val_raw.save_features(mfcc_transform, val_pt)\n",
    "\n",
    "train_dataset = FeaturesDataset(train_pt)\n",
    "test_dataset = FeaturesDataset(test_pt)\n",
    "val_dataset = FeaturesDataset(val_pt)\n",
    "\n",
    "\n",
    "print(\"¡Datasets cargados exitosamente!\")\n",
    "print(f\"Train samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab517a3b",
   "metadata": {},
   "source": [
    "# Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a695a9c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32453, 13, 101])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(train_dataset.features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6895b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1015\n",
      "Epoch 1/40\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Target 10 is out of bounds.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m model = RNNModel(rnn_type = \u001b[33m'\u001b[39m\u001b[33mRNN\u001b[39m\u001b[33m'\u001b[39m, n_input_channels=\u001b[32m101\u001b[39m)\n\u001b[32m      6\u001b[39m epochs = \u001b[32m40\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m all_curves, times = \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_evaluations_per_epoch\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_gpu\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m show_curves(all_curves)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Proyecto-EL4106/trainer.py:96\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model, train_dataset, val_dataset, epochs, criterion, batch_size, lr, n_evaluations_per_epoch, use_gpu)\u001b[39m\n\u001b[32m     93\u001b[39m     x_batch = x_batch.cuda()\n\u001b[32m     94\u001b[39m     y_batch = y_batch.cuda()\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m y_predicted, loss = \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_gpu\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     98\u001b[39m cumulative_train_loss += loss.item() * x_batch.shape[\u001b[32m0\u001b[39m]\n\u001b[32m     99\u001b[39m examples_count += y_batch.shape[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Proyecto-EL4106/trainer.py:11\u001b[39m, in \u001b[36mtrain_step\u001b[39m\u001b[34m(x_batch, y_batch, model, optimizer, criterion, use_gpu)\u001b[39m\n\u001b[32m      8\u001b[39m y_predicted = model(x_batch)\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Cálculo de loss\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m loss = \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_predicted\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Actualización de parámetros\u001b[39;00m\n\u001b[32m     14\u001b[39m optimizer.zero_grad()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Proyecto-EL4106/proyecto/lib/python3.12/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Proyecto-EL4106/proyecto/lib/python3.12/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Proyecto-EL4106/proyecto/lib/python3.12/site-packages/torch/nn/modules/loss.py:1310\u001b[39m, in \u001b[36mCrossEntropyLoss.forward\u001b[39m\u001b[34m(self, input, target)\u001b[39m\n\u001b[32m   1309\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) -> Tensor:\n\u001b[32m-> \u001b[39m\u001b[32m1310\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1311\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1312\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1313\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1314\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1315\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1316\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1317\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Proyecto-EL4106/proyecto/lib/python3.12/site-packages/torch/nn/functional.py:3462\u001b[39m, in \u001b[36mcross_entropy\u001b[39m\u001b[34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[39m\n\u001b[32m   3460\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   3461\u001b[39m     reduction = _Reduction.legacy_get_string(size_average, reduce)\n\u001b[32m-> \u001b[39m\u001b[32m3462\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_nn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3463\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3464\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3465\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3466\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3467\u001b[39m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3468\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3469\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mIndexError\u001b[39m: Target 10 is out of bounds."
     ]
    }
   ],
   "source": [
    "lr = 5e-4\n",
    "batch_size = 32\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "n_trains = 5\n",
    "model = RNNModel(rnn_type = 'RNN', n_input_channels=13)\n",
    "epochs = 40\n",
    "\n",
    "all_curves, times = train_model(model, train_dataset, val_dataset, epochs, criterion, batch_size, lr, n_evaluations_per_epoch=6, use_gpu=False)\n",
    "show_curves(all_curves)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proyecto (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
